import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import os

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# å°‚é–€å®¶ã®ç¨®é¡ã¨ãã‚Œãã‚Œã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®šç¾©
EXPERTS = {
    "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã€ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€æŠ€è¡“çš„ãªå•é¡Œè§£æ±ºã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "æ–™ç†å°‚é–€å®¶": "ã‚ãªãŸã¯ç†Ÿç·´ã—ãŸæ–™ç†ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¬ã‚·ãƒ”ã€èª¿ç†æ³•ã€é£Ÿæã®é¸ã³æ–¹ã€æ „é¤Šãƒãƒ©ãƒ³ã‚¹ã€ä¸–ç•Œå„å›½ã®æ–™ç†ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "æ—…è¡Œå°‚é–€å®¶": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ—…è¡Œã®å°‚é–€å®¶ã§ã™ã€‚æ—…è¡Œè¨ˆç”»ã€è¦³å…‰åœ°æƒ…å ±ã€äº¤é€šæ‰‹æ®µã€å®¿æ³Šæ–½è¨­ã€ç¾åœ°ã®æ–‡åŒ–ã‚„ç¿’æ…£ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "å¥åº·ãƒ»ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å°‚é–€å®¶": "ã‚ãªãŸã¯å¥åº·ã¨ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚é‹å‹•ã€æ „é¤Šã€å¥åº·ç®¡ç†ã€ã‚¹ãƒˆãƒ¬ã‚¹è§£æ¶ˆã€ã‚¦ã‚§ãƒ«ãƒã‚¹ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "ãƒ“ã‚¸ãƒã‚¹å°‚é–€å®¶": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ“ã‚¸ãƒã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚çµŒå–¶æˆ¦ç•¥ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€è²¡å‹™ç®¡ç†ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã€ã‚­ãƒ£ãƒªã‚¢é–‹ç™ºã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
}

def get_llm_response(user_input: str, expert_type: str) -> str:
    """
    LLMã‹ã‚‰å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        expert_type (str): é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ç¨®é¡
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    try:
        # ChatOpenAIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        system_message = EXPERTS.get(expert_type, "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
        messages = [
            SystemMessage(content=system_message),
            HumanMessage(content=user_input),
        ]
        
        # LLMã«è³ªå•ã‚’é€ä¿¡ã—ã€å›ç­”ã‚’å–å¾—
        result = llm.invoke(messages)
        return result.content
        
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - Streamlitã‚¢ãƒ—ãƒªã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¨æ©Ÿèƒ½ã‚’å®šç¾©"""
    
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨æ¦‚è¦èª¬æ˜
    st.title("ğŸ¤– AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # ã‚¢ãƒ—ãƒªã®æ¦‚è¦èª¬æ˜
    st.markdown("""
    ## ğŸ“‹ ã‚¢ãƒ—ãƒªã®æ¦‚è¦
    ã“ã®ã‚¢ãƒ—ãƒªã¯ã€æ§˜ã€…ãªåˆ†é‡ã®å°‚é–€å®¶AIã¨ãƒãƒ£ãƒƒãƒˆã§ãã‚‹Webã‚¢ãƒ—ãƒªã§ã™ã€‚
    å°‚é–€åˆ†é‡ã‚’é¸æŠã—ã¦ã€ãã®é ˜åŸŸã«ç‰¹åŒ–ã—ãŸè³ªå•ã‚„ç›¸è«‡ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
    
    ## ğŸ¯ ä½¿ç”¨æ–¹æ³•
    1. **å°‚é–€å®¶ã‚’é¸æŠ**: å³å´ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰ç›¸è«‡ã—ãŸã„åˆ†é‡ã®å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„
    2. **è³ªå•ã‚’å…¥åŠ›**: ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
    3. **é€ä¿¡**: ã€Œå›ç­”ã‚’å–å¾—ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å°‚é–€å®¶AIã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã—ã¦ãã ã•ã„
    
    ## âš¡ æ³¨æ„äº‹é …
    - OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆç’°å¢ƒå¤‰æ•° `OPENAI_API_KEY` ã«è¨­å®šï¼‰
    - å›ç­”ã®ç”Ÿæˆã«ã¯æ•°ç§’ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
    """)
    
    st.markdown("---")
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’2åˆ—ã«åˆ†å‰²
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’­ è³ªå•ãƒ»ç›¸è«‡å†…å®¹")
        user_input = st.text_area(
            "ã“ã¡ã‚‰ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
            height=150,
            placeholder="ä¾‹ï¼šåŠ¹ç‡çš„ãªPythonã‚³ãƒ¼ãƒ‰ã®æ›¸ãæ–¹ã‚’æ•™ãˆã¦ãã ã•ã„"
        )
    
    with col2:
        st.subheader("ğŸ‘¨â€ğŸ’¼ å°‚é–€å®¶ã‚’é¸æŠ")
        expert_type = st.radio(
            "ç›¸è«‡ã—ãŸã„åˆ†é‡ã®å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
            list(EXPERTS.keys()),
            help="é¸æŠã—ãŸå°‚é–€å®¶ã®åˆ†é‡ã«å¿œã˜ã¦ã€ã‚ˆã‚Šçš„ç¢ºãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™"
        )
    
    # é€ä¿¡ãƒœã‚¿ãƒ³
    if st.button("ğŸš€ å›ç­”ã‚’å–å¾—", type="primary", use_container_width=True):
        if user_input.strip():
            # å›ç­”ç”Ÿæˆä¸­ã®è¡¨ç¤º
            with st.spinner(f"{expert_type}ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                response = get_llm_response(user_input, expert_type)
            
            # å›ç­”ã®è¡¨ç¤º
            st.markdown("---")
            st.subheader(f"ğŸ’¡ {expert_type}ã‹ã‚‰ã®å›ç­”")
            
            # å›ç­”ã‚’ãã‚Œã„ã«è¡¨ç¤º
            st.markdown(f"""
            <div style="
                background-color: #f0f2f6;
                padding: 20px;
                border-radius: 10px;
                border-left: 5px solid #1f77b4;
                margin: 10px 0;
            ">
                {response}
            </div>
            """, unsafe_allow_html=True)
            
        else:
            st.warning("âš ï¸ è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¿½åŠ æƒ…å ±
    with st.sidebar:
        st.markdown("## â„¹ï¸ å°‚é–€å®¶ã®è©³ç´°")
        selected_expert_description = EXPERTS[expert_type]
        st.info(f"**{expert_type}**\n\n{selected_expert_description}")
        
        st.markdown("---")
        st.markdown("## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯")
        st.markdown("""
        - **Frontend**: Streamlit
        - **LLM**: OpenAI GPT-4o-mini
        - **Framework**: LangChain
        - **Deployment**: Streamlit Community Cloud
        """)

if __name__ == "__main__":
    main()